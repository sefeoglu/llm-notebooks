{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Code Credit: Hugging Face**\n\n**Dataset Credit: https://twitter.com/Dorialexander/status/1681671177696161794 **","metadata":{"id":"YO20b0TD5D4w"}},{"cell_type":"markdown","source":"## Finetune Llama-2-7b on a Google colab\n\nWelcome to this Google Colab notebook that shows how to fine-tune the recent Llama-2-7b model on a single Google colab and turn it into a chatbot\n\nWe will leverage PEFT library from Hugging Face ecosystem, as well as QLoRA for more memory efficient finetuning","metadata":{"id":"C2EgqEPDQ8v6"}},{"cell_type":"markdown","source":"## Setup\n\nRun the cells below to setup and install the required libraries. For our experiment we will need `accelerate`, `peft`, `transformers`, `datasets` and TRL to leverage the recent [`SFTTrainer`](https://huggingface.co/docs/trl/main/en/sft_trainer). We will use `bitsandbytes` to [quantize the base model into 4bit](https://huggingface.co/blog/4bit-transformers-bitsandbytes). We will also install `einops` as it is a requirement to load Falcon models.","metadata":{"id":"i-tTvEF1RT3y"}},{"cell_type":"code","source":"!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n!pip install -q datasets bitsandbytes einops wandb","metadata":{"id":"mNnkgBq7Q3EU","outputId":"806d7490-f248-48cd-df34-9e5d6519e336","execution":{"iopub.status.busy":"2023-07-23T18:51:08.096656Z","iopub.execute_input":"2023-07-23T18:51:08.097545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset\n\n","metadata":{"id":"Rnqmq7amRrU8"}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HF\")\nsecret_value_1 = user_secrets.get_secret(\"WaB\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(secret_value_0)","metadata":{"id":"niyf5_Kc4ugO","outputId":"3472dddc-7c9a-4dc3-ab8b-0fefd7e519eb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\n#dataset_name = \"timdettmers/openassistant-guanaco\" ###Human ,.,,,,,, ###Assistant\ndata_files = {\"train\": \"train_translate.csv\"}\ndataset_name = \"HoangHa/vi-lima-chatgpt\" #french novels\ndataset = load_dataset(dataset_name,  data_files=data_files, column_names=['prompt','answer'],use_auth_token=True)","metadata":{"id":"0X3kHnskSWU4","outputId":"ec40239b-0672-4f03-ef2b-9d74fb8a97e2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"id":"fY-f67ngnoeW","outputId":"25f140e2-db89-48ec-d057-4c8cf5012c35","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the model","metadata":{"id":"rjOMoSbGSxx9"}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\nfrom accelerate import infer_auto_device_map\nmodel_name = \"TinyPixel/Llama-2-7B-bf16-sharded\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    trust_remote_code=True,\n    device_map=\"auto\"\n)\nmodel.config.use_cache = False","metadata":{"id":"ZwXZbQ2dSwzI","outputId":"d3b8b298-9cb0-4693-afa2-04920f779d2e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's also load the tokenizer below","metadata":{"id":"xNqIYtQcUBSm"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"id":"XDS2yYmlUAD6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nlora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\n\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)","metadata":{"id":"dQdvjTYTT1vQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the trainer","metadata":{"id":"dzsYHLwIZoLm"}},{"cell_type":"markdown","source":"Here we will use the [`SFTTrainer` from TRL library](https://huggingface.co/docs/trl/main/en/sft_trainer) that gives a wrapper around transformers `Trainer` to easily fine-tune models on instruction based datasets using PEFT adapters. Let's first load the training arguments below.","metadata":{"id":"aTBJVE4PaJwK"}},{"cell_type":"code","source":"from transformers import TrainingArguments\n\noutput_dir = \"./results\"\nper_device_train_batch_size = 4\ngradient_accumulation_steps = 4\noptim = \"paged_adamw_32bit\"\nadam_beta1= 0.9\nadam_beta2= 0.95\n#save_steps = 100\nlogging_steps = 10\nlearning_rate = 2e-4\nmax_grad_norm = 0.3\n#max_steps = 200\nwarmup_ratio = 0.03\nlr_scheduler_type = \"constant\"\nweight_decay= 0.1\nnum_train_epochs=5\n\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    #save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    fp16=True,\n    max_grad_norm=max_grad_norm,\n    #max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=True,\n    lr_scheduler_type=lr_scheduler_type,\n    weight_decay=weight_decay,\n    adam_beta1= adam_beta1,\n    adam_beta2= adam_beta2,\n    num_train_epochs=num_train_epochs\n)","metadata":{"id":"OCFTvGW6aspE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def formatting_prompts_func(example):\n    output_texts = []\n    for i in range(len(example['prompt'])):\n        text = f\"\"\"\n        <s>[INST] <<SYS>>\n        {{Bạn là một trợ lý thông thái. Bạn sẽ trả lời câu hỏi với kiến thức như các chuyên gia}}\n        <</SYS>>\n        \n        {{Câu hỏi: {example['prompt'][i]}}} [/INST]\n        \n        {{Trả lời: {example['answer'][i]}}} </s>\n        \"\"\"\n        output_texts.append(text)\n    return output_texts\n","metadata":{"id":"kB9F_7XLSpqZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then finally pass everthing to the trainer","metadata":{"id":"I3t6b2TkcJwy"}},{"cell_type":"code","source":"from trl import SFTTrainer\n\nmax_seq_length = 4096\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset['train'],\n    peft_config=peft_config,\n    max_seq_length=max_seq_length,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    formatting_func=formatting_prompts_func,\n    packing=False\n)","metadata":{"id":"TNeOBgZeTl2H","outputId":"64f8f88c-2e15-4d6d-d7be-82f904fbefaf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will also pre-process the model by upcasting the layer norms in float 32 for more stable training","metadata":{"id":"GWplqqDjb3sS"}},{"cell_type":"code","source":"for name, module in trainer.model.named_modules():\n    if \"norm\" in name:\n        module = module.to(torch.float32)","metadata":{"id":"7OyIvEx7b1GT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the model","metadata":{"id":"1JApkSrCcL3O"}},{"cell_type":"markdown","source":"Now let's train the model! Simply call `trainer.train()`","metadata":{"id":"JjvisllacNZM"}},{"cell_type":"code","source":"trainer.train(secret_value_1)","metadata":{"id":"_kbS7nRxcMt7","outputId":"cef004fd-d78c-444a-caed-eb434a18bb39","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\nfrom trl import SFTTrainer\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\nfrom peft import LoraConfig, get_peft_model\nfrom accelerate import notebook_launcher\n\ndef train_trainer_ddp():\n    model_name = \"TinyPixel/Llama-2-7B-bf16-sharded\"\n\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.float16,\n    )\n\n    model = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        quantization_config=bnb_config,\n        trust_remote_code=True\n    )\n    model.config.use_cache = False\n    \n    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n    tokenizer.pad_token = tokenizer.eos_token\n\n    \n    lora_alpha = 16\n    lora_dropout = 0.1\n    lora_r = 64\n\n    peft_config = LoraConfig(\n        lora_alpha=lora_alpha,\n        lora_dropout=lora_dropout,\n        r=lora_r,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\"\n    )\n\n    \n    output_dir = \"./results\"\n    per_device_train_batch_size = 4\n    gradient_accumulation_steps = 4\n    num_train_epochs=5\n    optim = \"paged_adamw_32bit\"\n    save_steps = 100\n    logging_steps = 10\n    learning_rate = 2e-4\n    max_grad_norm = 0.3\n    max_steps = 100\n    warmup_ratio = 0.03\n    evaluation_strategy=\"epoch\"\n    lr_scheduler_type = \"constant\"\n\n    training_arguments = TrainingArguments(\n        output_dir=output_dir,\n        per_device_train_batch_size=per_device_train_batch_size,\n        gradient_accumulation_steps=gradient_accumulation_steps,\n        optim=optim,\n        save_steps=save_steps,\n        logging_steps=logging_steps,\n        learning_rate=learning_rate,\n        fp16=True,\n        max_grad_norm=max_grad_norm,\n        max_steps=max_steps,\n        warmup_ratio=warmup_ratio,\n        group_by_length=True,\n        lr_scheduler_type=lr_scheduler_type,\n        num_train_epochs=num_train_epochs,\n        evaluation_strategy=evaluation_strategy\n    )\n\n\n    max_seq_length = 4096\n\n    trainer = SFTTrainer(\n        model=model,\n        train_dataset=dataset['train'],\n        peft_config=peft_config,\n        dataset_text_field=\"conversations\",\n        max_seq_length=max_seq_length,\n        tokenizer=tokenizer,\n        args=training_arguments,\n    )\n    \n    \n    for name, module in trainer.model.named_modules():\n        if \"norm\" in name:\n            module = module.to(torch.float32)\n        \n    trainer.train()\n    \n    \nnotebook_launcher(train_trainer_ddp, args=(), num_processes=2)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"During training, the model should converge nicely as follows:\n\n![image](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/loss-falcon-7b.png)\n\nThe `SFTTrainer` also takes care of properly saving only the adapters during training instead of saving the entire model.","metadata":{"id":"H5c0ppfasK29"}},{"cell_type":"code","source":"model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model  # Take care of distributed/parallel training\nmodel_to_save.save_pretrained(\"outputs\")","metadata":{"id":"v2CEgCF14M0m","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lora_config = LoraConfig.from_pretrained('outputs')\nmodel = get_peft_model(model, lora_config)","metadata":{"id":"qmA4G6C64dJ4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = f\"\"\"\n        <s>[INST] <<SYS>>\n        {{Bạn là một trợ lý thông thái. Bạn sẽ trả lời câu hỏi với kiến thức như các chuyên gia}}\n        <</SYS>>\n        \n        {{Câu hỏi: {example['prompt'][i]}}} [/INST]\n        \n        {{Trả lời:\n        \"\"\"\ndevice = \"cuda:0\"\n\ninputs = tokenizer(text, return_tensors=\"pt\").to(device)\noutputs = model.generate(**inputs, max_new_tokens=512)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"id":"pgt86z-x4diG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.push_to_hub(\"llama2-qlora-vi-llama-v1\")","metadata":{"id":"fjOInz-Q-54k","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"cUmT5MRD_D9k"},"execution_count":null,"outputs":[]}]}